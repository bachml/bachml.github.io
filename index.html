<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Guohang Zeng</title>
  
  <meta name="author" content="Guohang Zeng">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Guohang Zeng</name>
              </p>
              <p>I am a final year M.Phil(Master of Philosophy) student at CS department of the University of Melbourne, advised by Prof. <a href="https://people.eng.unimelb.edu.au/baileyj/">James Bailey</a> and Dr. <a href="https://people.eng.unimelb.edu.au/smonazam/">Sarah Erfani</a>. Before comming to University of Melbourne, I got my B.Eng Degree in CS from Shenzhen University in 2016.
              </p> 

              <p>
                My interests mainly focus on deep learning, computer vision and interpretability.
              </p>


              <p>I am currently working at SenseTime as a research intern.
              </p>

              <p>Contact: guohangz[at]student.unimelb.edu.au
              </p>
            
              </p>
              <p style="text-align:center">
                <a href="mailto:guohangz@student.unimelb.edu.au">Email</a> &nbsp/&nbsp
                <a href="data/cv_new.pdf">Resume (in Chinese, outdated)</a> &nbsp/&nbsp
                <a href="https://scholar.google.com.au/citations?user=2dYfM9YAAAAJ&hl=en">Google Scholar</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/JonBarron.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/niming.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research Projects</heading>
              <p>
                I'm currently working on interpretable ML and its connection to adversarail ML. Much of my previous research were about deep learning and its applications on facial regonication.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/thumbnail.png" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
             
                <papertitle>Generating Deep Network Explanations with Robust Attribution Alignment
                </papertitle>
              
              <br>
              <strong>Guohang Zeng</strong>, Yousef Kowsar, Sarah Erfani, James Bailey
              <br>
              <em>ACML2021 (Long Oral)</em>
              <p>We proposed a novel attribution method and achieved good performance with light computational cost in CIFAR10 and TinyImageNet. (to appear)</p>
           
            </td>
          </tr>

          <p></p>
          <p></p>

       


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/fig2.png" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
             
                <papertitle>Hand-crafted Feature Guided Deep Learning for Facial Expression Recognition
                </papertitle>
              
              <br>
              <strong>Guohang Zeng</strong>, Jiancan Zhou, Xijia, Weicheng Xie, Linlin Shen
              <br>
              <em>International Conference on Automatic Face & Gesture Recognition</em>, 2018,  <a href="data/FG18.pdf">PDF</a> 
              <br>
             
              <p></p>
              <p>For facial expression recognition task, we proposed a hand-crafted feature guided network with a novel loss function and achieved state-of-the-art result on CK+ dataset.</p>
          
            </td>
          </tr>




          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/fig1.png" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
             
                <papertitle>Joint and collaborative representation with local adaptive convolution feature for face recognition with single sample per person
                </papertitle>
              
              <br>
              Meng Yang, Xin Wang, <strong>Guohang Zeng</strong>, Linlin Shen
              <br>
              <em>Pattern Recognition</em>, 2017, <a href="data/PR16.pdf">PDF</a>
              <br>
              
              <p></p>
              <p>We proposed a sparse representation-based classifier with deep learning for face recognition with single sample per person. Our method achieved state of the art results on several datasets.</p>
            </td>
          </tr>


        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Awards</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="10"><tbody>
          <tr>
            <td width="75%" valign="center">
              Melbourne University Graduate Scholarship, 2018
              <br><br>
              Shenzhen University Top Scholarship, 2014
              <br><br>
              Loongson Scholarship, 2013
            </td>
          </tr>
        </tbody></table>

</body>

</html>
