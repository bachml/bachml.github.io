<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Guohang Zeng</title>
  
  <meta name="author" content="Guohang Zeng">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Guohang Zeng</name>
              </p>
              <p>I am a final year M.Phil(Master of Philosophy) student at CS department of the University of Melbourne, advised by Prof. <a href="https://people.eng.unimelb.edu.au/baileyj/">James Bailey</a> and Dr. <a href="https://people.eng.unimelb.edu.au/smonazam/">Sarah Erfani</a>. Before comming to Univ of Melbourne, I got my B.Eng Degree in CS from Shenzhen University in 2016.
              </p> 

              <p>
                My interests mainly focus on deep learning and computer vision. I am also open to other topics, such like recommendation system and NLP.
              </p>


              <p>I am currently looking for an internship.
              </p>
            
              </p>
              <p style="text-align:center">
                <a href="mailto:guohangz@student.unimelb.edu.au">Email</a> &nbsp/&nbsp
                <a href="data/JonBarron-CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com.au/citations?user=2dYfM9YAAAAJ&hl=en">Google Scholar</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/JonBarron.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/niming.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research Projects</heading>
              <p>
                I'm currently working on interpretable ML and its connection to adversarail ML. Much of my previous research were about deep learning and its applications on facial regonication.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/fig4.png" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
             
                <papertitle>Generating Deep Network Explanations with Robust Attribution Alignment
                </papertitle>
              
              <br>
              <strong>Guohang Zeng</strong>, Yousef Kowsar, Sarah Monazam Erfani, James Bailey
              <br>
              <em>Pattern Recognition</em>, 2017
              <br>
              <a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/mcg/">project page</a> /
              <a href="data/PontTusetTPAMI2017.bib">bibtex</a> /
              <a href="https://drive.google.com/file/d/1AiB78Fy7QVA3KqgcooyzMAC5L8HhNzjz/view?usp=sharing">fast eigenvector code</a>
              <p></p>
              <p>We produce state-of-the-art contours, regions and object candidates, and we compute normalized-cuts eigenvectors 20&times faster.</p>
              <p>This paper subsumes our CVPR 2014 paper.</p>
            </td>
          </tr>



          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/fig3.png" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
             
                <papertitle>Learning Interpretable Deep Representation via Attention Mechanism for ICU Clinical Prediction Tasks
                </papertitle>
              
              <br>
              <strong>Guohang Zeng</strong>
              <br>
              <em>Pattern Recognition</em>, 2017
              <br>
              <a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/mcg/">project page</a> /
              <a href="data/PontTusetTPAMI2017.bib">bibtex</a> /
              <a href="https://drive.google.com/file/d/1AiB78Fy7QVA3KqgcooyzMAC5L8HhNzjz/view?usp=sharing">fast eigenvector code</a>
              <p></p>
              <p>We produce state-of-the-art contours, regions and object candidates, and we compute normalized-cuts eigenvectors 20&times faster.</p>
              <p>This paper subsumes our CVPR 2014 paper.</p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/fig2.png" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
             
                <papertitle>Hand-crafted Feature Guided Deep Learning for Facial Expression Recognition
                </papertitle>
              
              <br>
              <strong>Guohang Zeng</strong>, Jiancan Zhou, Xijia, Weicheng Xie, Linlin Shen
              <br>
              <em>International Conference on Automatic Face & Gesture Recognition</em>, 2018
              <br>
              <a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/mcg/">project page</a> /
              <a href="data/PontTusetTPAMI2017.bib">bibtex</a> /
              <a href="https://drive.google.com/file/d/1AiB78Fy7QVA3KqgcooyzMAC5L8HhNzjz/view?usp=sharing">fast eigenvector code</a>
              <p></p>
              <p>We produce state-of-the-art contours, regions and object candidates, and we compute normalized-cuts eigenvectors 20&times faster.</p>
              <p>This paper subsumes our CVPR 2014 paper.</p>
            </td>
          </tr>




          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/fig1.png" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
             
                <papertitle>Joint and collaborative representation with local adaptive convolution feature for face recognition with single sample per person
                </papertitle>
              
              <br>
              Meng Yang, Xin Wang, <strong>Guohang Zeng</strong>, Linlin Shen
              <br>
              <em>Pattern Recognition</em>, 2017
              <br>
              <a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/mcg/">project page</a> /
              <a href="data/PontTusetTPAMI2017.bib">bibtex</a> /
              <a href="https://drive.google.com/file/d/1AiB78Fy7QVA3KqgcooyzMAC5L8HhNzjz/view?usp=sharing">fast eigenvector code</a>
              <p></p>
              <p>We produce state-of-the-art contours, regions and object candidates, and we compute normalized-cuts eigenvectors 20&times faster.</p>
              <p>This paper subsumes our CVPR 2014 paper.</p>
            </td>
          </tr>


        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Awards</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="10"><tbody>
          <tr>
            <td width="75%" valign="center">
              Melbourne University Graduate Scholarship, 2018
              <br><br>
              Shenzhen University Top Scholarship, 2014
              <br><br>
              Loongson Scholarship, 2013
            </td>
          </tr>
        </tbody></table>

</body>

</html>
